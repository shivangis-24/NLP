{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN1F8JXdXikx",
        "outputId": "f9881044-3ead-454f-db7a-01ec731718c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.14)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "uEOmBcjFXsdt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "iQ3NTtYRX1lm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5VKtbHJX_H6",
        "outputId": "b1a2cb2a-2201-4fc9-a045-2a5b4358b2ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7ccca13437f0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "introduction_doc = nlp(\n",
        "    \"This tutorial is about Natural Language Processing in spaCy.\")"
      ],
      "metadata": {
        "id": "wqMZuK48YEXV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(introduction_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evVyWhC1YiWS",
        "outputId": "e58b0f89-69f9-42e2-d624-b2b4d3b58174"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[token.text for token in introduction_doc]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGye7XdjYjYe",
        "outputId": "114400ff-2d28-4322-9dda-947d02e1cfb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'tutorial',\n",
              " 'is',\n",
              " 'about',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'in',\n",
              " 'spaCy',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading in text from a file"
      ],
      "metadata": {
        "id": "GHRCowQqYmb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib"
      ],
      "metadata": {
        "id": "mmN-BbchY5q0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/introduction.txt\""
      ],
      "metadata": {
        "id": "20P8OTqAZg3_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "introduction_doc = nlp(pathlib.Path(file_name).read_text(encoding=\"UTF_8\"))"
      ],
      "metadata": {
        "id": "yZvu27SNY8VU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ([token.text for token in introduction_doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tOn4UMeZuhu",
        "outputId": "7d6e1c28-398e-4791-f238-d114845deb90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'tutorial', 'is', 'about', 'Natural', 'Lanuage', 'Processing', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "about_text = about_text = (\n",
        "...     \"Gus Proto is a Python developer currently\"\n",
        "...     \" working for a London-based Fintech\"\n",
        "...     \" company. He is interested in learning\"\n",
        "...     \" Natural Language Processing.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "5O4n8V7lZzJ4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_doc = nlp(about_text)"
      ],
      "metadata": {
        "id": "FOkN7B4FaIyu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = list(about_doc.sents)"
      ],
      "metadata": {
        "id": "ukKB6BlPaVQY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFbMn8qraY5E",
        "outputId": "3322e7e1-5f92-46b6-8bb2-d62f9668bcc6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  print(f\"{sentence[:5]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iMnarv3aX5i",
        "outputId": "d469eba9-b53d-4709-f2d3-fae28ba765fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gus Proto is a Python...\n",
            "He is interested in learning...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ellipsis_text = (\n",
        "...     \"Gus, can you, ... never mind, I forgot\"\n",
        "...     \" what I was saying. So, do you think\"\n",
        "...     \" we should ...\"\n",
        "... )"
      ],
      "metadata": {
        "id": "CNyseyKHae9I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language"
      ],
      "metadata": {
        "id": "4_7K9mFDbAow"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A decorator in Python is a design pattern that allows you to modify or enhance the behavior of functions or methods. It does this without permanently modifying the function itself. Decorators are often used for logging, enforcing access control, instrumentation, or modifying the behavior of existing code in a flexible, reusable way."
      ],
      "metadata": {
        "id": "BEIFXjBThBeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A decorator is typically defined as a higher-order function, which is a function that takes a function as input and returns a new function. The syntax for using a decorator involves prefixing a function definition with the decorator name, preceded by the @ symbol."
      ],
      "metadata": {
        "id": "EHBd4ubFhF6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The @Language.component Decorator:\n",
        "In the context of spaCy, the @Language.component decorator is used to register a custom pipeline component. A pipeline component is a function that processes a Doc object (a container for accessing linguistic annotations in spaCy) and returns it, potentially modifying it along the way."
      ],
      "metadata": {
        "id": "uU0IEmjvhQew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Component Registration: The decorator @Language.component(\"set_custom_boundaries\") is used to register the function set_custom_boundaries as a pipeline component. The string \"set_custom_boundaries\" is the name that will be used to refer to this component within the spaCy pipeline."
      ],
      "metadata": {
        "id": "hmWSGcOXhg5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@Language.component(\"set_custom_boundaries\")\n",
        "def set_custom_boundaries(doc):\n",
        "  \"\"\"Add support to use `...` as a delimiter for sentence detection\"\"\"\n",
        "  for token in doc[:-1]:\n",
        "    if token.text == \"...\":\n",
        "      doc[token.i + 1].is_sent_start = True\n",
        "  return doc"
      ],
      "metadata": {
        "id": "NZLeIJMJbDZn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "6FyWfRJ0bI5x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
        "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
        "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
        "for sentence in custom_ellipsis_sentences:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__gxHXbciznk",
        "outputId": "4b400b01-20a5-46e0-c2c7-c9bcd2ca8287"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gus, can you, ...\n",
            "never mind, I forgot what I was saying.\n",
            "So, do you think we should ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "0v9fwr9YsOHG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_text = (\n",
        "...     \"Gus Proto is a Python developer currently\"\n",
        "...     \" working for a London-based Fintech\"\n",
        "...     \" company. He is interested in learning\"\n",
        "...     \" Natural Language Processing.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "ifCv3DK9jkeK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_doc = nlp(about_text)"
      ],
      "metadata": {
        "id": "KKKnFp3Tr9zK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in about_doc:\n",
        "  print(token,token.idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP9FHn0HsVSn",
        "outputId": "0a8e09ae-a586-462a-e6e9-790d4f770d67"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gus 0\n",
            "Proto 4\n",
            "is 10\n",
            "a 13\n",
            "Python 15\n",
            "developer 22\n",
            "currently 32\n",
            "working 42\n",
            "for 50\n",
            "a 54\n",
            "London 56\n",
            "- 62\n",
            "based 63\n",
            "Fintech 69\n",
            "company 77\n",
            ". 84\n",
            "He 86\n",
            "is 89\n",
            "interested 92\n",
            "in 103\n",
            "learning 106\n",
            "Natural 115\n",
            "Language 123\n",
            "Processing 132\n",
            ". 142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    f\"{'Text with Whitespace':22}\"\n",
        "    f\"{'Is Alphanumeric?':15}\"\n",
        "    f\"{'Is Punctuation?':18}\"\n",
        "    f\"{'Is Stop Word?'}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "SzyBlmGTsdMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c02dee6-98a3-4f36-8951-851620b01ec5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text with Whitespace  Is Alphanumeric?Is Punctuation?   Is Stop Word?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in about_doc:\n",
        "  print(\n",
        "       f\"{str(token.text_with_ws):22}\"\n",
        "       f\"{str(token.is_alpha):15}\"\n",
        "       f\"{str(token.is_punct):18}\"\n",
        "       f\"{str(token.is_stop)}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBtQ9xmgwcs3",
        "outputId": "ef7ea8e2-b11e-4b57-dece-5679648ed546"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gus                   True           False             False\n",
            "Proto                 True           False             False\n",
            "is                    True           False             True\n",
            "a                     True           False             True\n",
            "Python                True           False             False\n",
            "developer             True           False             False\n",
            "currently             True           False             False\n",
            "working               True           False             False\n",
            "for                   True           False             True\n",
            "a                     True           False             True\n",
            "London                True           False             False\n",
            "-                     False          True              False\n",
            "based                 True           False             False\n",
            "Fintech               True           False             False\n",
            "company               True           False             False\n",
            ".                     False          True              False\n",
            "He                    True           False             True\n",
            "is                    True           False             True\n",
            "interested            True           False             False\n",
            "in                    True           False             True\n",
            "learning              True           False             False\n",
            "Natural               True           False             False\n",
            "Language              True           False             False\n",
            "Processing            True           False             False\n",
            ".                     False          True              False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ">>> custom_about_text = (\n",
        "  \"Gus Proto is a Python developer currently\"\n",
        "  \" working for a London@based Fintech\"\n",
        "  \" company. He is interested in learning\"\n",
        "  \" Natural Language Processing.\"\n",
        " )\n",
        "\n",
        "print([token.text for token in nlp(custom_about_text)[8:15]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR0Tw6jew4SP",
        "outputId": "72d86a0f-fadd-4e02-c03a-9e783595269c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['for', 'a', 'London@based', 'Fintech', 'company', '.', 'He']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a custom tokenizer"
      ],
      "metadata": {
        "id": "ukFORVUHxqYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "prefix_re = spacy.util.compile_prefix_regex(\n",
        "   custom_nlp.Defaults.prefixes\n",
        " )"
      ],
      "metadata": {
        "id": "2b0eo_UExeC2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_re = spacy.util.compile_suffix_regex(\n",
        "...     custom_nlp.Defaults.suffixes\n",
        "... )"
      ],
      "metadata": {
        "id": "l8FmqKo_x9Bl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_infixes = [r\"@\"]"
      ],
      "metadata": {
        "id": "IQvL0o2_yA4X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infix_re = spacy.util.compile_infix_regex(\n",
        "...     list(custom_nlp.Defaults.infixes) + custom_infixes\n",
        "... )"
      ],
      "metadata": {
        "id": "FA8ksHZhyDO-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_nlp.tokenizer = Tokenizer(\n",
        "...     nlp.vocab,\n",
        "...     prefix_search=prefix_re.search,\n",
        "...     suffix_search=suffix_re.search,\n",
        "...     infix_finditer=infix_re.finditer,\n",
        "...     token_match=None,\n",
        "... )"
      ],
      "metadata": {
        "id": "EMiz0Er4yFoF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tokenizer_about_doc = custom_nlp(custom_about_text)"
      ],
      "metadata": {
        "id": "jjeQ2wQsyOT0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([token.text for token in custom_tokenizer_about_doc[8:15]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loDIQFoyyTih",
        "outputId": "8c1c5734-ead4-4d7f-fe69-ace0d4f5fc7d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['for', 'a', 'London', '@', 'based', 'Fintech', 'company']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build a new Tokenizer, you generally provide it with:\n",
        "\n",
        "Vocab: A storage container for special cases, which is used to handle cases like contractions and emoticons.\n",
        "prefix_search: A function that handles preceding punctuation, such as opening parentheses.\n",
        "suffix_search: A function that handles succeeding punctuation, such as closing parentheses.\n",
        "infix_finditer: A function that handles non-whitespace separators, such as hyphens.\n",
        "token_match: An optional Boolean function that matches strings that should never be split. It overrides the previous rules and is useful for entities like URLs or numbers."
      ],
      "metadata": {
        "id": "WMUSbQ7o0aIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop Words"
      ],
      "metadata": {
        "id": "ScyENQKt0k51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
      ],
      "metadata": {
        "id": "mNBDOAMsyVzt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(spacy_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqy6Ik3X0oxs",
        "outputId": "b82b09cf-deb5-4fa5-ac32-9d2a1ccb8cb4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for stop_word in list(spacy_stopwords)[:10]:\n",
        "  print(stop_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUHUAL6W0rc-",
        "outputId": "19f0a6d1-93ce-4bd2-c5ff-b6f04299f4d6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one\n",
            "rather\n",
            "last\n",
            "are\n",
            "over\n",
            "because\n",
            "alone\n",
            "which\n",
            "perhaps\n",
            "indeed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ">>> custom_about_text = (\n",
        "...     \"Gus Proto is a Python developer currently\"\n",
        "...     \" working for a London-based Fintech\"\n",
        "...     \" company. He is interested in learning\"\n",
        "...     \" Natural Language Processing.\"\n",
        "... )\n",
        ">>> nlp = spacy.load(\"en_core_web_sm\")\n",
        ">>> about_doc = nlp(custom_about_text)\n",
        ">>> print([token for token in about_doc if not token.is_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ0Ub_Zn0wIw",
        "outputId": "d49eb244-a88f-4a51-c0fa-14b2cc2b6804"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Gus, Proto, Python, developer, currently, working, London, -, based, Fintech, company, ., interested, learning, Natural, Language, Processing, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "Ruz0tzU902sP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conference_help_text = (\n",
        "...     \"Gus is helping organize a developer\"\n",
        "...     \" conference on Applications of Natural Language\"\n",
        "...     \" Processing. He keeps organizing local Python meetups\"\n",
        "...     \" and several internal talks at his workplace.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "HV_VrB8H1I8_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conference_help_doc = nlp(conference_help_text)"
      ],
      "metadata": {
        "id": "9LhNDzRw1Ly0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "ZnASCOPy10fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in conference_help_doc:\n",
        "  if str(token) != str(token.lemma_):\n",
        "    print(f\"{str(token):>20} : {str(token.lemma_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRjplltW1Q_g",
        "outputId": "5ff30cdc-11ce-4959-ea92-6126303ee30c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  is : be\n",
            "                  He : he\n",
            "               keeps : keep\n",
            "          organizing : organize\n",
            "             meetups : meetup\n",
            "               talks : talk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you donâ€™t lemmatize the text, then organize and organizing will be counted as different tokens, even though they both refer to the same concept. Lemmatization helps you avoid duplicate words that may overlap conceptually."
      ],
      "metadata": {
        "id": "qsJbztbD2B-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "A5RgXQbD18Wd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "miG1efmT2P2S"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_text = (\n",
        "...     \"Gus Proto is a Python developer currently\"\n",
        "...     \" working for a London-based Fintech company. He is\"\n",
        "...     \" interested in learning Natural Language Processing.\"\n",
        "...     \" There is a developer conference happening on 21 July\"\n",
        "...     ' 2019 in London. It is titled \"Applications of Natural'\n",
        "...     ' Language Processing\". There is a helpline number'\n",
        "...     \" available at +44-1234567891. Gus is helping organize it.\"\n",
        "...     \" He keeps organizing local Python meetups and several\"\n",
        "...     \" internal talks at his workplace. Gus is also presenting\"\n",
        "...     ' a talk. The talk will introduce the reader about \"Use'\n",
        "...     ' cases of Natural Language Processing in Fintech\".'\n",
        "...     \" Apart from his work, he is very passionate about music.\"\n",
        "...     \" Gus is learning to play the Piano. He has enrolled\"\n",
        "...     \" himself in the weekend batch of Great Piano Academy.\"\n",
        "...     \" Great Piano Academy is situated in Mayfair or the City\"\n",
        "...     \" of London and has world-class piano instructors.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "R8OOF2Cr2nI1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_doc = nlp(complete_text)"
      ],
      "metadata": {
        "id": "9vCiFViR2pN9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\n",
        "...     token.text\n",
        "...     for token in complete_doc\n",
        "...     if not token.is_stop and not token.is_punct\n",
        "... ]"
      ],
      "metadata": {
        "id": "UqEi3qpE2sIh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> print(Counter(words).most_common(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbYcoAQv2vaz",
        "outputId": "fafaf76b-33f0-42c4-a2f0-c39400d931a3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Gus', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS tagging"
      ],
      "metadata": {
        "id": "Jmf1n4zU2784"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "oYUY0HZ-2yIu"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_text = (\n",
        "...     \"Gus Proto is a Python developer currently\"\n",
        "...     \" working for a London-based Fintech\"\n",
        "...     \" company. He is interested in learning\"\n",
        "...     \" Natural Language Processing.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "jQ_-st953BRh"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_doc = nlp(about_text)"
      ],
      "metadata": {
        "id": "GA91qNG_3Dql"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in about_doc:\n",
        "...     print(\n",
        "...         f\"\"\"\n",
        "... TOKEN: {str(token)}\n",
        "... =====\n",
        "... TAG: {str(token.tag_):10} POS: {token.pos_}\n",
        "... EXPLANATION: {spacy.explain(token.tag_)}\"\"\"\n",
        "...     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C4j1BzS3IhL",
        "outputId": "feed3bb9-9055-4249-8c59-1f9531e6141e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TOKEN: Gus\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: Proto\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: is\n",
            "=====\n",
            "TAG: VBZ        POS: AUX\n",
            "EXPLANATION: verb, 3rd person singular present\n",
            "\n",
            "TOKEN: a\n",
            "=====\n",
            "TAG: DT         POS: DET\n",
            "EXPLANATION: determiner\n",
            "\n",
            "TOKEN: Python\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: developer\n",
            "=====\n",
            "TAG: NN         POS: NOUN\n",
            "EXPLANATION: noun, singular or mass\n",
            "\n",
            "TOKEN: currently\n",
            "=====\n",
            "TAG: RB         POS: ADV\n",
            "EXPLANATION: adverb\n",
            "\n",
            "TOKEN: working\n",
            "=====\n",
            "TAG: VBG        POS: VERB\n",
            "EXPLANATION: verb, gerund or present participle\n",
            "\n",
            "TOKEN: for\n",
            "=====\n",
            "TAG: IN         POS: ADP\n",
            "EXPLANATION: conjunction, subordinating or preposition\n",
            "\n",
            "TOKEN: a\n",
            "=====\n",
            "TAG: DT         POS: DET\n",
            "EXPLANATION: determiner\n",
            "\n",
            "TOKEN: London\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: -\n",
            "=====\n",
            "TAG: HYPH       POS: PUNCT\n",
            "EXPLANATION: punctuation mark, hyphen\n",
            "\n",
            "TOKEN: based\n",
            "=====\n",
            "TAG: VBN        POS: VERB\n",
            "EXPLANATION: verb, past participle\n",
            "\n",
            "TOKEN: Fintech\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: company\n",
            "=====\n",
            "TAG: NN         POS: NOUN\n",
            "EXPLANATION: noun, singular or mass\n",
            "\n",
            "TOKEN: .\n",
            "=====\n",
            "TAG: .          POS: PUNCT\n",
            "EXPLANATION: punctuation mark, sentence closer\n",
            "\n",
            "TOKEN: He\n",
            "=====\n",
            "TAG: PRP        POS: PRON\n",
            "EXPLANATION: pronoun, personal\n",
            "\n",
            "TOKEN: is\n",
            "=====\n",
            "TAG: VBZ        POS: AUX\n",
            "EXPLANATION: verb, 3rd person singular present\n",
            "\n",
            "TOKEN: interested\n",
            "=====\n",
            "TAG: JJ         POS: ADJ\n",
            "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
            "\n",
            "TOKEN: in\n",
            "=====\n",
            "TAG: IN         POS: ADP\n",
            "EXPLANATION: conjunction, subordinating or preposition\n",
            "\n",
            "TOKEN: learning\n",
            "=====\n",
            "TAG: VBG        POS: VERB\n",
            "EXPLANATION: verb, gerund or present participle\n",
            "\n",
            "TOKEN: Natural\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: Language\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: Processing\n",
            "=====\n",
            "TAG: NNP        POS: PROPN\n",
            "EXPLANATION: noun, proper singular\n",
            "\n",
            "TOKEN: .\n",
            "=====\n",
            "TAG: .          POS: PUNCT\n",
            "EXPLANATION: punctuation mark, sentence closer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = []\n",
        "adjectives = []\n",
        "for token in about_doc:\n",
        "   if token.pos_ == \"NOUN\":\n",
        "    nouns.append(token)\n",
        "   if token.pos_ == \"ADJ\":\n",
        "            adjectives.append(token)"
      ],
      "metadata": {
        "id": "E6tQPEj73Owf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nouns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK6ozFEUCMzZ",
        "outputId": "12c46558-2c4d-4f88-c00f-aa8061eed400"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[developer, company]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adjectives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSK3_I6ECXbZ",
        "outputId": "60b8305d-c07e-4e2b-9924-2778350710b9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[interested]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization : using displacy"
      ],
      "metadata": {
        "id": "lijhglZbCmQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "uFEjLx11CYjs"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "BU-gGz6WCkM0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_interest_text = (\n",
        "...     \"He is interested in learning Natural Language Processing.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "7qy_dqzoCra7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_interest_doc = nlp(about_interest_text)"
      ],
      "metadata": {
        "id": "mFupooC2CzGW"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.serve(about_interest_doc, style=\"dep\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiX_Iyn5C1_X",
        "outputId": "41026527-e2de-4813-f184-26f41d3e80c3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(about_interest_doc, style=\"dep\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "G5QQ0ABLC4a9",
        "outputId": "4f499a3b-3062-4445-f149-6bc89973552e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c69c485cb3634b0f826672f54f021c38-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c69c485cb3634b0f826672f54f021c38-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c69c485cb3634b0f826672f54f021c38-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c69c485cb3634b0f826672f54f021c38-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c69c485cb3634b0f826672f54f021c38-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c69c485cb3634b0f826672f54f021c38-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c69c485cb3634b0f826672f54f021c38-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c69c485cb3634b0f826672f54f021c38-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c69c485cb3634b0f826672f54f021c38-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c69c485cb3634b0f826672f54f021c38-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c69c485cb3634b0f826672f54f021c38-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c69c485cb3634b0f826672f54f021c38-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c69c485cb3634b0f826672f54f021c38-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c69c485cb3634b0f826672f54f021c38-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c69c485cb3634b0f826672f54f021c38-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_text = (\n",
        "...     \"Gus Proto is a Python developer currently\"\n",
        "...     \" working for a London-based Fintech company. He is\"\n",
        "...     \" interested in learning Natural Language Processing.\"\n",
        "...     \" There is a developer conference happening on 21 July\"\n",
        "...     ' 2019 in London. It is titled \"Applications of Natural'\n",
        "...     ' Language Processing\". There is a helpline number'\n",
        "...     \" available at +44-1234567891. Gus is helping organize it.\"\n",
        "...     \" He keeps organizing local Python meetups and several\"\n",
        "...     \" internal talks at his workplace. Gus is also presenting\"\n",
        "...     ' a talk. The talk will introduce the reader about \"Use'\n",
        "...     ' cases of Natural Language Processing in Fintech\".'\n",
        "...     \" Apart from his work, he is very passionate about music.\"\n",
        "...     \" Gus is learning to play the Piano. He has enrolled\"\n",
        "...     \" himself in the weekend batch of Great Piano Academy.\"\n",
        "...     \" Great Piano Academy is situated in Mayfair or the City\"\n",
        "...     \" of London and has world-class piano instructors.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "FSz-JLg7Mdak"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_doc = nlp(complete_text)"
      ],
      "metadata": {
        "id": "CH0FLbFzMtnr"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_token_allowed(token):\n",
        "  return bool(\n",
        "         token\n",
        "         and str(token).strip()\n",
        "         and not token.is_stop\n",
        "         and not token.is_punct\n",
        "     )"
      ],
      "metadata": {
        "id": "iEob0R_XMtp-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_token(token):\n",
        "...     return token.lemma_.strip().lower()"
      ],
      "metadata": {
        "id": "M4_IdigVM3mz"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_filtered_tokens = [\n",
        "...     preprocess_token(token)\n",
        "...     for token in complete_doc\n",
        "...     if is_token_allowed(token)\n",
        "... ]"
      ],
      "metadata": {
        "id": "KWPOipBnM3pM"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzixoSrXM_Yh",
        "outputId": "00018d3a-f44c-4903-9ea2-abfc5d07e6a8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gus',\n",
              " 'proto',\n",
              " 'python',\n",
              " 'developer',\n",
              " 'currently',\n",
              " 'work',\n",
              " 'london',\n",
              " 'base',\n",
              " 'fintech',\n",
              " 'company',\n",
              " 'interested',\n",
              " 'learn',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'developer',\n",
              " 'conference',\n",
              " 'happen',\n",
              " '21',\n",
              " 'july',\n",
              " '2019',\n",
              " 'london',\n",
              " 'title',\n",
              " 'application',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'helpline',\n",
              " 'number',\n",
              " 'available',\n",
              " '+44',\n",
              " '1234567891',\n",
              " 'gus',\n",
              " 'helping',\n",
              " 'organize',\n",
              " 'keep',\n",
              " 'organize',\n",
              " 'local',\n",
              " 'python',\n",
              " 'meetup',\n",
              " 'internal',\n",
              " 'talk',\n",
              " 'workplace',\n",
              " 'gus',\n",
              " 'present',\n",
              " 'talk',\n",
              " 'talk',\n",
              " 'introduce',\n",
              " 'reader',\n",
              " 'use',\n",
              " 'case',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " 'fintech',\n",
              " 'apart',\n",
              " 'work',\n",
              " 'passionate',\n",
              " 'music',\n",
              " 'gus',\n",
              " 'learn',\n",
              " 'play',\n",
              " 'piano',\n",
              " 'enrol',\n",
              " 'weekend',\n",
              " 'batch',\n",
              " 'great',\n",
              " 'piano',\n",
              " 'academy',\n",
              " 'great',\n",
              " 'piano',\n",
              " 'academy',\n",
              " 'situate',\n",
              " 'mayfair',\n",
              " 'city',\n",
              " 'london',\n",
              " 'world',\n",
              " 'class',\n",
              " 'piano',\n",
              " 'instructor']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "Rsd7snz0NEDZ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load a spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize the Matcher with the shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Function to extract phone number\n",
        "def extract_phone_number(nlp_doc):\n",
        "    pattern = [\n",
        "        {\"ORTH\": \"(\"},\n",
        "        {\"SHAPE\": \"ddd\"},\n",
        "        {\"ORTH\": \")\"},\n",
        "        {\"SHAPE\": \"ddd\"},\n",
        "        {\"ORTH\": \"-\", \"OP\": \"?\"},\n",
        "        {\"SHAPE\": \"dddd\"},\n",
        "    ]\n",
        "    matcher.add(\"PHONE_NUMBER\", [pattern])\n",
        "    matches = matcher(nlp_doc)\n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_doc[start:end]\n",
        "        return span.text\n",
        "\n",
        "# Text to process\n",
        "conference_org_text = (\"There is a developer conference\"\n",
        "    \" happening on 21 July 2019 in London. It is titled\"\n",
        "    ' \"Applications of Natural Language Processing\".'\n",
        "    \" There is a helpline number available\"\n",
        "    \" at (123) 456-7891\")\n",
        "\n",
        "# Process the text\n",
        "conference_org_doc = nlp(conference_org_text)\n",
        "\n",
        "# Extract phone number\n",
        "phone_number = extract_phone_number(conference_org_doc)\n",
        "print(phone_number)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM1m8K-7PZzU",
        "outputId": "987a14d4-dcf0-4024-a821-cca0aadbe403"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(123) 456-7891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependency parsing using SpaCy"
      ],
      "metadata": {
        "id": "f-ekaN9_Qza2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "piano_text = \"Gus is learning piano\""
      ],
      "metadata": {
        "id": "KoQnU49wPzep"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "piano_doc = nlp(piano_text)"
      ],
      "metadata": {
        "id": "1H-IlHnNPzhi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in piano_doc:\n",
        "  print(\n",
        "      f\"\"\"\n",
        "TOKEN: {token.text}\n",
        "  )\n",
        "=====\n",
        "{token.tag_ = }\n",
        "{token.head.text = }\n",
        "{token.dep_ = }\"\"\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt_bRJ8VPzkE",
        "outputId": "a7626a43-b6cb-415b-9a87-ebe14382239e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TOKEN: Gus\n",
            "  )\n",
            "=====\n",
            "token.tag_ = 'NNP'\n",
            "token.head.text = 'learning'\n",
            "token.dep_ = 'nsubj'\n",
            "\n",
            "TOKEN: is\n",
            "  )\n",
            "=====\n",
            "token.tag_ = 'VBZ'\n",
            "token.head.text = 'learning'\n",
            "token.dep_ = 'aux'\n",
            "\n",
            "TOKEN: learning\n",
            "  )\n",
            "=====\n",
            "token.tag_ = 'VBG'\n",
            "token.head.text = 'learning'\n",
            "token.dep_ = 'ROOT'\n",
            "\n",
            "TOKEN: piano\n",
            "  )\n",
            "=====\n",
            "token.tag_ = 'NN'\n",
            "token.head.text = 'learning'\n",
            "token.dep_ = 'dobj'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_line_about_text = (\n",
        "...     \"Gus Proto is a Python developer\"\n",
        "...     \" currently working for a London-based Fintech company\"\n",
        "... )"
      ],
      "metadata": {
        "id": "pX48zjj5RzSa"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_line_about_doc = nlp(one_line_about_text)"
      ],
      "metadata": {
        "id": "i_-yETm4RxAq"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract children of `developer`\n",
        ">>> print([token.text for token in one_line_about_doc[5].children])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei3aaXizR6U1",
        "outputId": "916e2799-993a-4bd6-9b89-7e5405dbd3f6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'Python', 'working']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract previous neighboring node of `developer`\n",
        ">>> print (one_line_about_doc[5].nbor(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBuBSBhVjWfA",
        "outputId": "541f62d7-8ed0-441d-94f0-b266574c3a36"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract next neighboring node of `developer`\n",
        ">>> print (one_line_about_doc[5].nbor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LrJBKaejnyy",
        "outputId": "03c779ce-60c6-419b-d257-de92d72c7826"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "currently\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all tokens on the left of `developer`\n",
        "print([token.text for token in one_line_about_doc[5].lefts])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es08lT0XjqgX",
        "outputId": "d5f372bf-12b9-41b3-904f-e5c100fddab8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tokens on the right of `developer`\n",
        ">>> print([token.text for token in one_line_about_doc[5].rights])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt6It5eZjuTj",
        "outputId": "78d7c28c-56c2-4db6-a2f0-2530baf5b2c9"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['working']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print subtree of `developer`\n",
        ">>> print (list(one_line_about_doc[5].subtree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmtyS7f7j0Es",
        "outputId": "01a5b536-e531-4d09-fb46-1f352b58b0d6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[a, Python, developer, currently, working, for, a, London, -, based, Fintech, company]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "1jGpzTa3j311"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noun Phrase detection"
      ],
      "metadata": {
        "id": "RIe2yUMSlE1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conference_text = (\n",
        "...     \"There is a developer conference happening on 21 July 2019 in London.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "FjTuOH5HkggH"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conference_doc = nlp(conference_text)"
      ],
      "metadata": {
        "id": "K_aePtFlkjOL"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in conference_doc.noun_chunks:\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urWJRw0_kmYh",
        "outputId": "7cc146e1-c1eb-449a-8306-e8d04f845aa6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a developer conference\n",
            "21 July\n",
            "London\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verb Phrase Detection"
      ],
      "metadata": {
        "id": "bnGajmQJlHVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzcjqw8JlONP",
        "outputId": "67d8d847-b149-47c6-a76c-1028952b9cd8"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textacy\n",
            "  Downloading textacy-0.13.0-py3-none-any.whl (210 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/210.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m204.8/210.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (5.3.2)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.0.10)\n",
            "Collecting cytoolz>=0.10.1 (from textacy)\n",
            "  Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting floret~=0.10.0 (from textacy)\n",
            "  Downloading floret-0.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jellyfish>=0.8.0 (from textacy)\n",
            "  Downloading jellyfish-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.3.2)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.23.5)\n",
            "Collecting pyphen>=0.10.0 (from textacy)\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.2.2)\n",
            "Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.6.1)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.10/dist-packages (from textacy) (4.66.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->textacy) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.4.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.10.14)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy~=3.0->textacy) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (4.5.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy~=3.0->textacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy~=3.0->textacy) (2.1.4)\n",
            "Installing collected packages: pyphen, jellyfish, floret, cytoolz, textacy\n",
            "Successfully installed cytoolz-0.12.3 floret-0.10.5 jellyfish-1.0.3 pyphen-0.14.0 textacy-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textacy"
      ],
      "metadata": {
        "id": "Yfjgg-urk-0P"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_talk_text = (\n",
        "...     \"The talk will introduce reader about use\"\n",
        "...     \" cases of Natural Language Processing in\"\n",
        "...     \" Fintech, making use of\"\n",
        "...     \" interesting examples along the way.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "Cu64W8TJlNEJ"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]"
      ],
      "metadata": {
        "id": "5Hq7-0s-lXGV"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "about_talk_doc = textacy.make_spacy_doc(\n",
        "...     about_talk_text, lang=\"en_core_web_sm\"\n",
        "... )"
      ],
      "metadata": {
        "id": "Ldo-7E7slZX1"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verb_phrases = textacy.extract.token_matches(\n",
        "...     about_talk_doc, patterns=patterns\n",
        "... )"
      ],
      "metadata": {
        "id": "OVwCVehVleXM"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all verb phrases\n",
        ">>> for chunk in verb_phrases:\n",
        "...     print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7TsgAyxl0_t",
        "outputId": "db11a3d9-587b-4aee-8b76-9a34a7e8728b"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "will introduce\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract noun phrase to explain what nouns are involved\n",
        ">>> for chunk in about_talk_doc.noun_chunks:\n",
        "...     print (chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okf2yQJel6Gr",
        "outputId": "9e8005a2-0c0c-423a-c52d-32410d92c2b1"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The talk\n",
            "reader\n",
            "use cases\n",
            "Natural Language Processing\n",
            "Fintech\n",
            "use\n",
            "interesting examples\n",
            "the way\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Entity Recognition"
      ],
      "metadata": {
        "id": "sI6i3INcogdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "piano_class_text = (\n",
        "...     \"Great Piano Academy is situated\"\n",
        "...     \" in Mayfair or the City of London and has\"\n",
        "...     \" world-class piano instructors.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "CfUXjLGdl8yo"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "piano_class_doc = nlp(piano_class_text)"
      ],
      "metadata": {
        "id": "x06eJYYBomVg"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in piano_class_doc.ents:\n",
        "...     print(\n",
        "...         f\"\"\"\n",
        "... {ent.text = }\n",
        "... {ent.start_char = }\n",
        "... {ent.end_char = }\n",
        "... {ent.label_ = }\n",
        "... spacy.explain('{ent.label_}') = {spacy.explain(ent.label_)}\"\"\"\n",
        "... )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgqblJrmooKL",
        "outputId": "e7489b06-63de-4ef8-fab2-eeeca91261c6"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ent.text = 'Great Piano Academy'\n",
            "ent.start_char = 0\n",
            "ent.end_char = 19\n",
            "ent.label_ = 'ORG'\n",
            "spacy.explain('ORG') = Companies, agencies, institutions, etc.\n",
            "\n",
            "ent.text = 'Mayfair'\n",
            "ent.start_char = 35\n",
            "ent.end_char = 42\n",
            "ent.label_ = 'GPE'\n",
            "spacy.explain('GPE') = Countries, cities, states\n",
            "\n",
            "ent.text = 'the City of London'\n",
            "ent.start_char = 46\n",
            "ent.end_char = 64\n",
            "ent.label_ = 'GPE'\n",
            "spacy.explain('GPE') = Countries, cities, states\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "survey_text = (\n",
        "...     \"Out of 5 people surveyed, James Robert,\"\n",
        "...     \" Julie Fuller and Benjamin Brooks like\"\n",
        "...     \" apples. Kelly Cox and Matthew Evans\"\n",
        "...     \" like oranges.\"\n",
        "... )"
      ],
      "metadata": {
        "id": "15pWv0fForiJ"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_person_names(token):\n",
        "...     if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
        "           return \"[REDACTED] \"\n",
        "...     return token.text_with_ws"
      ],
      "metadata": {
        "id": "TA22JTb-o14H"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_names(nlp_doc):\n",
        "...     with nlp_doc.retokenize() as retokenizer:\n",
        "...         for ent in nlp_doc.ents:\n",
        "...             retokenizer.merge(ent)\n",
        "...     tokens = map(replace_person_names, nlp_doc)\n",
        "...     return \"\".join(tokens)"
      ],
      "metadata": {
        "id": "eP05JUAQpGKo"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "survey_doc = nlp(survey_text)"
      ],
      "metadata": {
        "id": "5CG6xvw9ptN9"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(redact_names(survey_doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYO-KdApptQn",
        "outputId": "2a722445-c4ac-4e4c-b6b2-41fa75663fc3"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 5 people surveyed, [REDACTED] , [REDACTED] and [REDACTED] like apples. [REDACTED] and [REDACTED] like oranges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0aTDztXpymK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}